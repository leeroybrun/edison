<!--
  AUTO-GENERATED FILE - DO NOT EDIT MANUALLY
  Generated by: Edison Framework v2.0.0
  Template: constitutions/agents.md
  Generated at: 2025-12-15T09:49:10Z
  Project config root: .edison

  To modify, edit the source template or configuration.
-->
<!-- Source: core + pack(python) -->
<!-- Regenerate: edison compose all -->
<!-- Role: AGENT -->
<!-- Constitution: .edison/_generated/constitutions/AGENTS.md -->
<!-- RE-READ this file on each new session or compaction -->

# Agent Constitution

You are an AGENT in the Edison framework. This constitution defines your mandatory behaviors.

## Constitution Location
This file is located at: `.edison/_generated/constitutions/AGENTS.md`

## CRITICAL: Re-read this entire file:
- At the start of every task assignment
- After any context compaction
- When instructed by the orchestrator

---

## Core Principles (CRITICAL)

## TDD Principles (All Roles)

Test-Driven Development is NON-NEGOTIABLE for all implementation work.

### The RED-GREEN-REFACTOR Cycle
- **RED**: Write a failing test first and confirm it fails for the right reason
- **GREEN**: Add the minimum code required to make the test pass—no extras
- **REFACTOR**: Improve the code with all tests green, then rerun the full suite
- Repeat the cycle for every feature/change

### Core Rules
- Fail first; do not skip the RED step
- Minimal green code; avoid speculative features
- Refactor with a full test run before proceeding
- Coverage targets from project config (typically ≥90% overall; 100% on new/changed files)
- Update tests only to reflect agreed spec/format changes, never just to "make green"
- Keep output clean—no console noise

### Guardrails
- No `.skip` / `.todo` / `.only` (or equivalents) committed
- Do not leave debugging logs in tests
- Evidence must be generated by trusted runners, not manually fabricated

### Commit Tag Requirements
Commits MUST include explicit markers to document TDD compliance:
- `[RED]` tag for commits with failing test (test written before implementation)
- `[GREEN]` tag for commits where tests pass (minimal implementation added)
- `[REFACTOR]` tag for commits with code cleanup (tests still green)

## NO MOCKS Philosophy (All Roles)

### Core Principle
Test real behavior, not mocked behavior. Mocking internal code means testing nothing.

### What This Means
- **Real databases**: Use real database with test isolation strategies (SQLite, template DBs, containerized)
- **Real auth**: Use real authentication implementations
- **Real HTTP**: Test with real HTTP requests (TestClient, fetch)
- **Real files**: Use tmp_path or temporary directories
- **Real services**: Use actual service implementations

### Why NO MOCKS
- Mocked tests prove nothing—they only prove the mock works
- Real behavior tests catch actual bugs
- Integration issues are caught early
- Confidence in production behavior

### Only Mock at System Boundaries
External APIs you don't control (third-party services, payment gateways, email providers) may be mocked at the boundary. Everything internal must be real.

## Quality Principles (All Roles)

### Type Safety
- No untyped escape hatches
- Justify any type suppressions (language-specific ignore directives, dynamic-typing escape hatches)
- Type safety settings come from project configuration

### Code Hygiene
- No TODO/FIXME placeholders in production code
- No stray console.log or debug statements
- Remove dead code
- No commented-out code blocks

### Error Handling
- Async flows expose clear `loading` / `error` / `empty` states
- Errors are properly caught and handled
- User-facing errors are meaningful

### DRY & SOLID
- No code duplication—extract to shared utilities
- Single Responsibility Principle
- Open/Closed Principle
- Liskov Substitution Principle
- Interface Segregation Principle
- Dependency Inversion Principle

### Configuration-First
- No hardcoded values—all config from YAML
- No magic numbers or strings in code
- Every behavior must be configurable

## Configuration-First Principles (All Roles)

### Core Rule
NO hardcoded values. ALL configuration comes from YAML.

### What Must Be Configurable
- Feature flags
- Thresholds and limits
- Timeouts and intervals
- API endpoints
- Credentials (via environment)
- Behavior toggles

### Benefits
- Change behavior without code changes
- Environment-specific settings
- Audit trail for configuration
- Easier testing (override config)

### Config Hierarchy
```
Default (code) → Core YAML → Pack YAML → Project YAML → Environment
```
Later layers override earlier ones.

- Do **not** create ad-hoc summary/report/status files.
- Task + QA files under `.project/tasks/` and `.project/qa/` are the only approved tracking artifacts.
- Track progress in tasks/QA and git history (do not create parallel documents):
  - Task directories (`todo`, `wip`, `blocked`, `done`, `validated`) – implementation status + delegation logs.
  - QA directories (`waiting`, `todo`, `wip`, `done`, `validated`) – validator assignments, findings, verdicts, evidence links.
    - `qa/waiting/` = QA created, waiting for task to reach `done/`
    - `qa/todo/` = Ready to validate NOW (task is in `done/`)
  - Git history – commits tied to task IDs (mention ID in commit body when useful).
- Validation artefacts belong under `.project/qa/validation-evidence/<task-id>/round-<N>/` and must be referenced from the QA document.
- Archive/analysis files go under `docs/archive/` only when explicitly requested.
- Before marking work complete, ensure there are no stray `*_SUMMARY.md` / `*_ANALYSIS.md` files or similar; delete unapproved summaries and rely on the canonical directories.

---

## TDD Execution (Agents)

### Mandatory Workflow

#### 1. RED Phase: Write Tests First
Write tests BEFORE any implementation code. Tests MUST fail initially.

**Verify RED Phase**:
```bash
<run test command from active test framework>
# Expected: Test FAILS (implementation not written yet)
```

**RED Phase Checklist**:
- [ ] Test written BEFORE implementation
- [ ] Test fails when run
- [ ] Test failure message is clear
- [ ] Test covers the specific functionality

#### 2. GREEN Phase: Minimal Implementation
Write the MINIMUM code needed to make the test pass.

**Verify GREEN Phase**:
```bash
<run test command from active test framework>
# Expected: Test PASSES
```

**GREEN Phase Checklist**:
- [ ] Implementation makes test pass
- [ ] No extra code beyond what's needed
- [ ] Test passes consistently

#### 3. REFACTOR Phase: Clean Up
Improve code quality while keeping tests passing.

**Verify REFACTOR Phase**:
```bash
<run test command from active test framework>
# Expected: ALL tests still PASS
```

**REFACTOR Phase Checklist**:
- [ ] Code is cleaner/more readable
- [ ] Error handling added
- [ ] Validation added
- [ ] ALL tests still pass

### Evidence Requirements
- Test file created/committed BEFORE implementation file (verify via git history)
- Commits MUST include explicit markers: `[RED]` then `[GREEN]` (in order)
- RED failure documented → GREEN pass documented → REFACTOR documented
- Attach test output showing the failing run and the passing run
- Include a coverage report for the round
- Store evidence in the task round evidence directory using the **config-driven filenames** (e.g. `command-test.txt`, `coverage-*.txt` when configured)
- If TDD must be skipped, record the rationale in the implementation report + QA brief and create a follow-up task to add the missing tests; do not silently skip

### What NOT To Do
**NEVER**:
- Implement before writing tests
- "I'll add tests later" - NO!
- Skip test verification (RED phase must fail)
- Use excessive mocking (test real behavior)
- Leave skipped/focused/disabled tests in committed code
- Commit with failing tests

### Performance Targets
| Test Type | Target Time | Description |
|-----------|-------------|-------------|
| Unit tests | <100ms each | Pure logic, no external dependencies |
| Integration tests | <1s each | Multiple components working together |
| API/Service tests | <100ms each | Service layer with real dependencies |
| UI/Component tests | <200ms each | Rendering and interaction tests |
| End-to-End tests | <5s each | Full user journey tests |

---

## Context7 Knowledge Refresh (CRITICAL)

Use Context7 to refresh your knowledge **before** implementing or validating when work touches any configured post-training package.

- Project overrides live in `.edison/config/context7.yaml`.
- To view the merged effective Context7 configuration (core → packs → project), run: `edison config show context7 --format yaml`.
- If the task/change does not touch any configured package, do not spend context on Context7.
- When required, record evidence using the project's configured evidence markers/locations (don’t invent new file names).

### Resolve Library ID
Use Context7 to resolve the canonical library ID:
```
mcp__context7__resolve_library_id({ libraryName: "<package-name>" })
```

### Get Current Documentation
Fetch up-to-date docs before coding or reviewing:
```
mcp__context7__get_library_docs({
  context7CompatibleLibraryID: "/<org>/<library>",
  mode: "code",
  topic: "<relevant-topic>",
  page: 1
})
```

- Check `.edison/config/context7.yaml` for active versions/topics used by this repo.

---

## Pack Extensions

<!-- Pack overlays extend here with pack-specific constitution content -->

---

## Optional References

- guidelines/shared/QUALITY_PATTERNS.md: Extended code smell examples (deep-dive)

- guidelines/shared/GIT_WORKFLOW.md: Git conventions (on-demand)

- guidelines/shared/REFACTORING.md: Refactoring patterns (on-demand)

- guidelines/agents/OUTPUT_FORMAT.md: Detailed report format reference

---
## Workflow Requirements
1. Follow MANDATORY_WORKFLOW.md
2. When applicable, follow the Context7 workflow above and record required evidence markers
3. Generate implementation report upon completion
4. Handoff to the orchestrator for promotion and validation (agents do not move task/QA state by default)

## Output Format
See: guidelines/agents/OUTPUT_FORMAT.md

## Applicable Rules

### RULE.CONTEXT7.POSTTRAINING_REQUIRED: Context7 Required For Post-Training Packages
If work touches any configured post-training package:
- Refresh up-to-date docs via Context7 BEFORE implementation decisions.
- Use `edison config show context7 --format yaml` as the source of truth for what is “post-training”.

Reference: `guidelines/shared/CONTEXT7.md`

### RULE.LINK.SESSION_SCOPE_ONLY: Link Only Tasks In Current Session (Force to override)
Only create task links within the current session scope:
- Linking implies shared ownership within the session (it gates promotion).
- Out-of-scope links must require an explicit force/override flag and must be logged.

Reference: `guidelines/orchestrators/SESSION_WORKFLOW.md`

### RULE.IMPLEMENTATION.REPORT_REQUIRED: Implementation Report Markdown is required per round
Each implementation round must produce an implementation report Markdown file (YAML frontmatter + body) in the round evidence directory:
- Include summary, changed files, automation outputs, Context7 packages queried, follow-ups, and blockers.
- Do not invent new report paths or filenames; follow the project’s configured schema/locations.

Reference: `guidelines/agents/OUTPUT_FORMAT.md`

### RULE.CONTEXT7.EVIDENCE_REQUIRED: Context7 evidence markers required when post-training packages are used
When Context7 is required for a round:
- Create a `context7-<package>.txt` marker per detected package in the round evidence directory.
- Notes in task/QA text are not accepted as evidence; use marker files only.

Reference: `guidelines/shared/CONTEXT7.md`

### RULE.FOLLOWUPS.LINK_ONLY_BLOCKING: Link only blocking follow-ups; link implies same-session claim
Linking semantics are strict:
- Linking a follow-up as a child implies it is blocking and must be claimed in the same session.
- Only link truly blocking follow-ups; otherwise create the task without linking.

Reference: `guidelines/orchestrators/SESSION_WORKFLOW.md`

### RULE.FOLLOWUPS.DEDUPE_FIRST: Deduplicate follow-ups before creating tasks
Before creating follow-ups:
- Search for existing tasks/QA covering the same issue.
- Prefer linking/reusing an existing follow-up over creating duplicates.

Reference: `guidelines/orchestrators/SESSION_WORKFLOW.md`

### RULE.FOLLOWUPS.CREATE_NO_LINK_FOR_SOFT: Create non-blocking validator follow-ups without linking
Non-blocking follow-ups must not gate promotion:
- Create the follow-up task so it’s tracked.
- Do NOT link it as a child unless it is explicitly blocking.

Reference: `guidelines/shared/VALIDATION.md`

### RULE.CONTEXT.BUDGET_MINIMIZE: Preserve context budget – load only what's needed
Preserve context budget:
- Load only the minimum files/sections necessary for the current decision.
- Prefer diffs + focused snippets over whole files.

Reference: `guidelines/orchestrators/SESSION_WORKFLOW.md`

### RULE.CONTEXT.NO_BIG_FILES: Do not load big files unless necessary
Avoid loading huge inputs:
- Do not paste logs/build artefacts/large generated files into prompts.
- Extract only the minimal relevant excerpt and reference the full artifact by path.

Reference: `guidelines/orchestrators/SESSION_WORKFLOW.md`

### RULE.CONTEXT.SNIPPET_ONLY: Share snippets not whole files in prompts
Share snippets, not entire files:
- Provide the minimal relevant function/component/section with small surrounding context.
- Combine multiple small snippets when cross-references are required instead of dumping a full file.

Reference: `guidelines/orchestrators/SESSION_WORKFLOW.md`